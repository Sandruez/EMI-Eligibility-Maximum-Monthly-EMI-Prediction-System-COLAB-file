{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["FJNUwmbgGyua","w6K7xa23Elo4","mDgbUHAGgjLW"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Project Name**    - EMIPredict AI ( Intelligent Financial Risk Assessment Platform )\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - Classification + Regression (Supervised learning)\n","##### **Contribution**    - Individual\n","##### **Team Member 1 -Chandraprakash kahar"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["### -: Financial Risk Assessment and EMI Prediction Platform using MLflow and Streamlit\n","\n","The Financial Risk Assessment and EMI Prediction Platform is an end-to-end machine learning solution designed to improve loan decision-making and financial planning. The project addresses the growing issue of EMI defaults caused by poor risk assessment by developing a data-driven platform capable of predicting EMI eligibility and estimating the maximum affordable EMI for individuals.\n","\n","Built using a dataset of 400,000 financial records with 22 demographic and economic variables, the system performs dual ML tasks‚Äîa classification model for EMI eligibility prediction and a regression model for maximum EMI amount estimation. Extensive feature engineering was applied to derive meaningful attributes such as credit utilization ratio, EMI-to-income ratio, and financial health score, improving the interpretability and performance of the models.\n","\n","The platform leverages MLflow for experiment tracking and model comparison, ensuring efficient management of model versions, hyperparameters, and metrics. This integration enables reproducible experimentation and streamlined model optimization. A range of algorithms‚Äîincluding Logistic Regression, Random Forest, XGBoost, and Linear Regression‚Äîwere evaluated using metrics such as accuracy, F1-score, mean squared error (MSE), and R¬≤ to ensure robust predictive capability.\n","\n","To make the solution accessible and interactive, a Streamlit-based web application was developed. Users can input personal and financial data to instantly view EMI eligibility results, estimated EMI limits, and visual insights into their financial health. The system also includes CRUD functionalities for managing financial records, enabling seamless data updates and historical tracking.\n","\n","Deployed on Streamlit Cloud, the platform offers a production-ready, scalable, and user-friendly interface for real-time financial risk assessment.\n","\n","‚öì Overall, this project demonstrates how machine learning, model tracking, and web technologies can be integrated into a comprehensive FinTech solution. It not only showcases technical expertise in end-to-end ML development but also delivers practical impact by helping individuals and financial institutions make smarter, data-driven loan decisions."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["https://github.com/Sandruez/EMI-Eligibility-Maximum-Monthly-EMI-Prediction-System.git"],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# Mlflow Analysis Link:-"],"metadata":{"id":"z06zY20fEwSM"}},{"cell_type":"markdown","source":["https://dagshub.com/chandrapapr1501/MLflow-model-tracking.mlflow/#/compare-experiments/s?experiments=%5B%223%22%2C%224%22%2C%225%22%2C%226%22%5D&searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D"],"metadata":{"id":"uIQuEG6VE2SQ"}},{"cell_type":"markdown","source":["# Streamlit App Link:"],"metadata":{"id":"R64vLopcFDlx"}},{"cell_type":"markdown","source":["https://emi-insights-app.streamlit.app/"],"metadata":{"id":"z50bSbCUFMSn"}},{"cell_type":"code","source":[],"metadata":{"id":"b_CB9ILLEvJF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["<u>Problem Statement</u>\n","\n","In the modern financial ecosystem, individuals frequently face difficulties in managing their EMIs (Equated Monthly Instalments) due to inadequate financial planning and insufficient risk assessment. Traditional methods of evaluating creditworthiness often fail to capture complex financial patterns and behavioral variables, leading to inaccurate lending decisions and higher default risks.\n","\n","To address this issue, the project aims to build a comprehensive Financial Risk Assessment Platform that leverages machine learning models integrated with MLflow for efficient experiment tracking and model management. The platform is designed to provide data-driven insights that enhance loan decision-making, improve financial literacy, and enable users to assess their EMI eligibility in real time.\n","\n","\n","\n","The system focuses on delivering the following key capabilities:\n","\n"," * Dual ML problem solving: Classification for EMI eligibility prediction and Regression for estimating the maximum EMI amount.\n","\n"," * Real-time financial risk assessment using a dataset of over 400,000 financial records.\n","\n"," * Advanced feature engineering from 22 financial and demographic variables to enhance model interpretability.\n","\n"," * MLflow integration for experiment tracking, versioning, and performance comparison.\n","\n"," * Interactive Streamlit Cloud deployment for scalable, production-ready web access.\n","\n"," * Complete CRUD operations for managing and maintaining financial data seamlessly.\n","\n","This platform aims to bridge the gap between financial decision-making and intelligent analytics, enabling both individuals and financial institutions to make more informed, transparent, and responsible lending choices."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***Step 1: Data Loading and Preprocessing\n","* Load the provided dataset of 400,000 realistic financial records across 5 EMI scenarios\n","* Implement comprehensive data cleaning for missing values, inconsistencies, and duplicates\n","* Apply data quality assessment and validation checks\n","* Create train-test-validation splits for model development\n","***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Load Dataset\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_file_path='/content/drive/MyDrive/Labmentix intern projects/EMIPredict AI /emi_prediction_dataset.csv'\n","#Loading of provided dataset of 400,000 realistic financial records across 5 EMI scenarios\n","df=pd.read_csv(data_file_path)"],"metadata":{"id":"AICtCvKnY3GT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","print(\"Number of rows in the dataset:\", df.shape[0])\n","print(\"Number of columns in the dataset:\", df.shape[1])"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Implementing comprehensive data cleaning for missing values, inconsistencies, and duplicates"],"metadata":{"id":"zCIFaVMCque5"}},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","dup_count=df.duplicated().sum()\n","print(f'Number of duplicate entries are :{dup_count}')"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","df.isna().sum()"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the missing values\n","plt.figure(figsize=(10,8))\n","sns.barplot(x=df.isnull().sum().index,y=df.isnull().sum())\n","plt.xticks(rotation=45)\n","plt.title('Missing Values Count')\n","plt.show()"],"metadata":{"id":"3q5wnI3om9sJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DtkuSn9wcX-b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did we know about our dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["Dataset Scale:\n","\n","* Total Records: 400,000 financial profiles\n","* Input Features: 22 comprehensive variables\n","* Target Variables: 2 (Classification + Regression)\n","* EMI Scenarios: 5 lending categories with realistic distributions\n","\n","EMI Scenario Distribution:\n","* E-commerce Shopping EMI (80,000 records) - Amount: 10K-200K, Tenure: 3-24 months\n","* Home Appliances EMI (80,000 records) - Amount: 20K-300K, Tenure: 6-36 months\n","* Vehicle EMI (80,000 records) - Amount: 80K-1500K, Tenure: 12-84 months\n","* Personal Loan EMI (80,000 records) - Amount: 50K-1000K, Tenure: 12-60 months\n","* Education EMI (80,000 records) - Amount: 50K-500K, Tenure: 6-48 months\n","\n","<u>Dataset Explanation</u>\n","\n","Input Features (22 Variables):\n","\n","  Personal Demographics:\n","* age: Customer age (25-60 years)\n","* gender: Gender classification (Male/Female)\n","* marital_status: Marital status (Single/Married)\n","* education: Educational qualification (High School/Graduate/Post Graduate/Professional)\n","\n","Employment and Income:\n","* monthly_salary: Monthly gross salary (15K-200K INR)\n","* employment_type: Employment category (Private/Government/Self-employed)\n","* years_of_employment: Work experience duration\n","* company_type: Organization size and type\n","\n","Housing and Family:\n","* house_type: Residential ownership status (Rented/Own/Family)\n","* monthly_rent: Monthly rental expenses\n","* family_size: Total household members\n","* dependents: Number of financial dependents\n","\n","Monthly Financial Obligations:\n","* school_fees: Educational expenses for dependents\n","* college_fees: Higher education costs\n","* travel_expenses: Monthly transportation costs\n","* groceries_utilities: Essential living expenses\n","* other_monthly_expenses: Miscellaneous financial obligations\n","\n","Financial Status and Credit History:\n","* existing_loans: Current loan obligations status\n","* current_emi_amount: Existing monthly EMI burden\n","* credit_score: Credit worthiness score (300-850)\n","* bank_balance: Current account balance\n","* emergency_fund: Available emergency savings\n","\n","Loan Application Details:\n","* emi_scenario: Type of EMI application (5 categories)\n","* requested_amount: Desired loan amount\n","* requested_tenure: Preferred repayment period in months\n","\n","Target Variables:\n","Classification Target:\n","* emi_eligibility: Primary classification target with 3 classes\n","     * Eligible: Low risk, comfortable EMI affordability\n","     * High_Risk: Marginal case, requires higher interest rates\n","     * Not_Eligible: High risk, loan not recommended\n","\n","Regression Target:\n","* max_monthly_emi: Primary regression target\n","     * Continuous variable representing maximum safe monthly EMI amount (500-50000 INR)\n","     * Calculated using comprehensive financial capacity analysis"],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding dataset Variables/Features***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","df.columns.to_list()"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","df.describe()\n"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables Description"],"metadata":{"id":"PBTbrJXOngz2"}},{"cell_type":"markdown","source":["\n","<u>Dataset Explanation</u>\n","\n","Input Features (22 Variables):\n","\n","  Personal Demographics:\n","* age: Customer age (25-60 years)\n","* gender: Gender classification (Male/Female)\n","* marital_status: Marital status (Single/Married)\n","* education: Educational qualification (High School/Graduate/Post Graduate/Professional)\n","\n","Employment and Income:\n","* monthly_salary: Monthly gross salary (15K-200K INR)\n","* employment_type: Employment category (Private/Government/Self-employed)\n","* years_of_employment: Work experience duration\n","* company_type: Organization size and type\n","\n","Housing and Family:\n","* house_type: Residential ownership status (Rented/Own/Family)\n","* monthly_rent: Monthly rental expenses\n","* family_size: Total household members\n","* dependents: Number of financial dependents\n","\n","Monthly Financial Obligations:\n","* school_fees: Educational expenses for dependents\n","* college_fees: Higher education costs\n","* travel_expenses: Monthly transportation costs\n","* groceries_utilities: Essential living expenses\n","* other_monthly_expenses: Miscellaneous financial obligations\n","\n","Financial Status and Credit History:\n","* existing_loans: Current loan obligations status\n","* current_emi_amount: Existing monthly EMI burden\n","* credit_score: Credit worthiness score (300-850)\n","* bank_balance: Current account balance\n","* emergency_fund: Available emergency savings\n","\n","Loan Application Details:\n","* emi_scenario: Type of EMI application (5 categories)\n","* requested_amount: Desired loan amount\n","* requested_tenure: Preferred repayment period in months\n","\n","Target Variables:\n","Classification Target:\n","* emi_eligibility: Primary classification target with 3 classes\n","     * Eligible: Low risk, comfortable EMI affordability\n","     * High_Risk: Marginal case, requires higher interest rates\n","     * Not_Eligible: High risk, loan not recommended\n","\n","Regression Target:\n","* max_monthly_emi: Primary regression target\n","     * Continuous variable representing maximum safe monthly EMI amount (500-50000 INR)\n","     * Calculated using comprehensive financial capacity analysisAnswer Here"],"metadata":{"id":"aJV4KIxSnxay"}},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["#Making gender feature/column consistent\n","gender_dict={\n","  'male':'Male','m':'Male','f':'Female', 'female':'Female'\n","            }\n","temp = df['gender'].astype(str).str.lower().map(gender_dict)\n"],"metadata":{"id":"W9IlP7G-iEK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.gender.value_counts().index"],"metadata":{"id":"YMZWL4PYk3Bw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.gender=temp"],"metadata":{"id":"N64vZExrrRnk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.gender.value_counts()"],"metadata":{"id":"oSCmWZbRkFRF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WOl0M5FXho9F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","unique_values = df.nunique()\n","unique_values"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **  Handling missing values"],"metadata":{"id":"DAQ00WEvsKUP"}},{"cell_type":"code","source":["df.isna().sum()"],"metadata":{"id":"TKVJXyDPrhJu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["** Missing %\tRecommended Action\tReason :-\n","\n","    < 1%  |\tSafe to drop rows\tVery small data loss; |  negligible impact\n","\n","    1 ‚Äì 5% |\tUsually drop or impute|\tContext-dependent\n","\n","    > 5%\t| Consider imputation or model-based filling\t| Too much information lost if dropped\n","\n","    > 30%\t| Often drop the column |\tNot enough data to be useful"],"metadata":{"id":"dVp_jXRUuGWx"}},{"cell_type":"markdown","source":["### Handling missing values in Education column."],"metadata":{"id":"9lkSV7jW8mIW"}},{"cell_type":"code","source":["print(f'1. % Missing values in education column :{(df.education.isna().sum()/len(df))*100}')"],"metadata":{"id":"hgYCTdinsWzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Acc. to recomendations....\n","# % missing values in education column <1% (~0.6<1) ,so droping it create negligible empact.\n","df.dropna(subset=['education'],inplace=True)"],"metadata":{"id":"9suK1KDrstgO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Handling missing values in Monthly rented column."],"metadata":{"id":"hOGqj3CM8vEl"}},{"cell_type":"code","source":["print(f'2. % Missing values in monthly_rent column :{(df.monthly_rent.isna().sum()/len(df))*100}')"],"metadata":{"id":"EHMBv1TfveI7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.monthly_rent.median()"],"metadata":{"id":"F6mYK34SxlVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[(df.house_type=='Rented') & (df.monthly_rent.isna())].shape"],"metadata":{"id":"W3IewsGEy37f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def helper_fun(x):\n","#   if x.house_type=='Rented' and np.isnan(x.monthly_rent):\n","#     return x\n","#   elif (x.house_type=='Own' or x.house_type=='Family') and np.isnan(x.monthly_rent):\n","#     x.monthly_rent=0\n","#     return x\n","#   else :\n","#     return x\n"],"metadata":{"id":"P_6cSbhd0xJt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# temp=df.copy()\n","# temp=temp.apply(helper_fun,axis=1)"],"metadata":{"id":"jAhd64nk0Tvp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp=df.copy()"],"metadata":{"id":"rqNwzq6j5tRX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Acc. to recomendations....\n","# % missing values in monthly_rent column <1% (~0.6<1) , in which those house_type are in [Own ,Family ] are filled with 0 and\n","#  Rented place holders are so droping,which create negligible empact.\n","\n","\n","temp.reset_index(drop=True,inplace=True)\n","# For 'Own' or 'Family' houses where rent is missing, set rent = 0\n","temp.loc[(temp['house_type'].isin(['Own', 'Family'])) & (temp['monthly_rent'].isna()), 'monthly_rent'] = 0\n","df=temp.copy()\n"],"metadata":{"id":"vFGzraga4K4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Droping values with Nan in monthly_rent col...\n","df.dropna(subset=['monthly_rent'],inplace=True)"],"metadata":{"id":"aFfDSQn37aLI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.monthly_rent.isna().sum()/len(df)*100"],"metadata":{"id":"zxq3puXq220-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"FfV_U7s4_RhT"}},{"cell_type":"code","source":["# ‚úÖ Step 1 ‚Äî Inspect the bad entries\n","\n","# Check what‚Äôs inside:\n","temp=df.copy()\n","\n","\n","# or see non-numeric rows:\n","\n","temp[~temp['bank_balance'].astype(str).str.replace('.', '', 1).str.isdigit()].head()\n","\n","\n","# We‚Äôll likely see things like '73500.0.0' or '48000.'.\n","\n","\n"],"metadata":{"id":"7VEgajbC_ROG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ‚úÖ Step 2 ‚Äî Clean and convert properly\n","\n","# We can sanitize those malformed values before converting:\n","\n","\n","# Convert to string first\n","temp['bank_balance'] = temp['bank_balance'].astype(str)\n","\n","# Fix malformed entries like '73500.0.0' ‚Üí '73500.0'\n","temp['bank_balance'] = temp['bank_balance'].str.replace(r'\\.0\\.', '.', regex=True)\n","\n","# Remove any stray non-numeric characters\n","temp['bank_balance'] = temp['bank_balance'].str.replace(r'[^0-9\\.]', '', regex=True)\n","\n","# Convert safely to float\n","temp['bank_balance'] = pd.to_numeric(temp['bank_balance'], errors='coerce')\n","\n"],"metadata":{"id":"nAb5Vn3hEdn3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ‚úÖ After this:\n","\n","temp['bank_balance'].dtype\n","# expected Output: float64\n"],"metadata":{"id":"D0ZYwiR9EUBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp[~temp['bank_balance'].astype(str).str.replace('.', '', 1).str.isdigit()].head()\n"],"metadata":{"id":"5PjTKi2VCnSh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=temp.copy()"],"metadata":{"id":"C7suajoxDQLt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Dealing with ['bank_balance',\"emergency_fund\",'credit_score'] columns Null values.."],"metadata":{"id":"21DDd8FNUy4d"}},{"cell_type":"code","source":["df[['bank_balance',\"emergency_fund\",'credit_score']].skew()"],"metadata":{"id":"98f2b3Fu76gw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### üìä <u>Skewness Summary</u>\n","Column\tSkewness\tDistribution Type\tInterpretation\n","\n","|--------------------|------------------|----------------|\n","\n","\n","\n","| Column | Skewness | Distribution | Interpretation |\n","| :--- | :------: | ----: | ----:|\n","|bank_balance |\t+1.415 |Right-skewed |\tLong tail to the right ‚Äî few people with very high balances |\n","|emergency_fund |+1.791|Right-skewed\t| A few people have very large funds|\n","| credit_score |‚Äì1.097|Left-skewed\tMost people have high credit scores; a few have very low ones|\n","\n","\n","\n","üß† <u>What This Means</u>\n","\n","* Right-skewed ‚Üí use median for imputation and optionally apply a log transform (np.log1p).\n","\n","* Left-skewed ‚Üí use mean for imputation (if not extreme), and you can mirror the data (if needed for modeling)."],"metadata":{"id":"43DhGPsQUuOF"}},{"cell_type":"markdown","source":["***‚úÖ Step-by-Step Recommendation"],"metadata":{"id":"FR9XviM_Wn0v"}},{"cell_type":"code","source":["# 1Ô∏è‚É£Ô∏è bank_balance\n","\n","# Skewness = 1.415 ‚Üí moderately right-skewed\n","# ‚úÖ Impute with median\n","# ‚úÖ Optional: apply log transform for normalization\n","\n","df['bank_balance'] = df['bank_balance'].fillna(df['bank_balance'].median())\n","# df['bank_balance_log'] = np.log1p(df['bank_balance'])"],"metadata":{"id":"vT6I1qwmyTG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2Ô∏è‚É£ emergency_fund\n","\n","# Skewness = 1.791 ‚Üí strongly right-skewed\n","# ‚úÖ Impute with median\n","# ‚úÖ Apply log transform (definitely helps)\n","\n","df['emergency_fund'] = df['emergency_fund'].fillna(df['emergency_fund'].median())\n","# df['emergency_fund_log'] = np.log1p(df['emergency_fund'])"],"metadata":{"id":"DKlVjRCiW4_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3Ô∏è‚É£ credit_score\n","\n","# Skewness = ‚Äì1.097 ‚Üí left-skewed\n","# ‚úÖ Impute with mean (median would be biased lower)\n","# ‚öôÔ∏è Optional: transform if needed (e.g., mirror or box-cox)\n","\n","df['credit_score'] = df['credit_score'].fillna(df['credit_score'].mean())\n"],"metadata":{"id":"R6rwsZKAW_E8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.age.value_counts()"],"metadata":{"id":"ZuaCkASkbT_V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Inspecting bad entries in monthly salary column"],"metadata":{"id":"DpLprkEUdAgr"}},{"cell_type":"code","source":["## # ‚úÖ Step 1 ‚Äî Inspect the bad entries\n","df[~df['monthly_salary'].astype(str).str.replace('.', '', 1).str.isdigit()].head()\n"],"metadata":{"id":"Es2aHMaDbxu9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ‚úÖ Step 2 ‚Äî Clean and convert properly\n","\n","# We can sanitize those malformed values before converting:\n","\n","temp=df.copy()\n","# Convert to string first\n","temp['monthly_salary'] = temp['monthly_salary'].astype(str)\n","\n","# Fix malformed entries like '73500.0.0' ‚Üí '73500.0'\n","temp['monthly_salary'] = temp['monthly_salary'].str.replace(r'\\.0\\.', '.', regex=True)\n","\n","# Remove any stray non-numeric characters\n","temp['monthly_salary'] = temp['monthly_salary'].str.replace(r'[^0-9\\.]', '', regex=True)\n","\n","# Convert safely to float\n","temp['monthly_salary'] = pd.to_numeric(temp['monthly_salary'], errors='coerce')\n","\n"],"metadata":{"id":"t7_hwixKcsB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## # ‚úÖ Step 1 ‚Äî Inspect the bad entries\n","temp[~temp['monthly_salary'].astype(str).str.replace('.', '', 1).str.isdigit()].head()\n"],"metadata":{"id":"NssbnzX4dfQU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp.dropna(subset=['monthly_salary'],inplace=True)"],"metadata":{"id":"n8V7FdgfotRY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=temp.copy()"],"metadata":{"id":"xD9YhdUTqPs_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## # ‚úÖ Step 1 ‚Äî Inspect the bad entries\n","df[~df['monthly_salary'].astype(str).str.replace('.', '', 1).str.isdigit()].head()\n"],"metadata":{"id":"KIE3zPtzdttd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df[df.monthly_salary.astype(str).str.count(r'\\.0')==1]"],"metadata":{"id":"OpGsZB1idoTU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Step 2 ‚Äî Dealing with the bad entries (eg:- 56.0.0 -> 56.0)\n","\n","# df[df.age.astype(str).str.count(r'\\.0')==1]\n","# Convert to string first\n","df['age'] = df['age'].astype(str)\n","\n","# Fix malformed entries like '73500.0.0' ‚Üí '73500.0'\n","df['age'] = df['age'].str.replace(r'\\.0\\.', '.', regex=True)\n","\n","# Convert safely to float\n","df['age'] = pd.to_numeric(df['age'], errors='coerce')\n"],"metadata":{"id":"atUnboYsHAPi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aGduN9zjtp1F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 2: Exploratory Data Analysis (EDA)\n","\n","* Analyze EMI eligibility distribution patterns across different lending scenarios\n","* Study correlation between financial variables and loan approval rates\n","* Investigate demographic patterns and risk factor relationships\n","* Generate comprehensive statistical summaries and business insights\n"],"metadata":{"id":"_kJBcxuBYwBe"}},{"cell_type":"code","source":["temp_df=df.copy()\n","temp_df.existing_loans= temp_df.existing_loans.map({'Yes':1,'No':0})\n","temp_df.existing_loans.value_counts()"],"metadata":{"id":"7NHydIZZuxLh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_temp=df.copy()"],"metadata":{"id":"TjKvXTTbvcm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=temp_df.copy()\n","df.existing_loans.value_counts()"],"metadata":{"id":"VK1CVk9Yvhtk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ----------------------------------------------------------\n","# üì¶ Import Libraries\n","# ----------------------------------------------------------\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Set plot style\n","sns.set(style=\"whitegrid\", palette=\"pastel\")\n","plt.rcParams['figure.figsize'] = (8, 5)\n","\n","# ----------------------------------------------------------\n","# 1Ô∏è‚É£ Statistical Overview\n","# ----------------------------------------------------------\n","print(\"üìã Data Overview:\")\n","display(df.head())\n","\n","print(\"\\nüî¢ Basic Info:\")\n","df.info()\n","\n","print(\"\\nüìà Statistical Summary (Numerical Columns):\")\n","display(df.describe().T)\n","\n","print(\"\\nüìä Missing Value %:\")\n","display((df.isna().sum() / len(df) * 100).sort_values(ascending=False))\n","\n","# ----------------------------------------------------------\n","# 2Ô∏è‚É£ EMI Eligibility Distribution\n","# ----------------------------------------------------------\n","print(\"\\nüéØ EMI Eligibility Distribution:\")\n","emi_dist = df['emi_eligibility'].value_counts(normalize=True) * 100\n","print(emi_dist)\n","\n","sns.countplot(x='emi_eligibility', data=df, hue='emi_scenario', palette='coolwarm')\n","plt.title(\"EMI Eligibility Across Different Lending Scenarios\")\n","plt.xlabel(\"EMI Eligibility (Yes / No)\")\n","plt.ylabel(\"Count\")\n","plt.legend(title=\"EMI Scenario\")\n","plt.show()\n","\n","# ----------------------------------------------------------\n","# 3Ô∏è‚É£ Financial Correlation Study\n","# ----------------------------------------------------------\n","financial_cols = [\n","    'monthly_salary', 'monthly_rent', 'school_fees', 'college_fees',\n","    'travel_expenses', 'groceries_utilities', 'other_monthly_expenses',\n","    'existing_loans', 'current_emi_amount', 'credit_score',\n","    'bank_balance', 'emergency_fund', 'requested_amount', 'max_monthly_emi'\n","]\n","\n","# Correlation Matrix\n","corr = df[financial_cols].corr()\n","plt.figure(figsize=(12,8))\n","sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n","plt.title(\"üîó Correlation Between Financial Variables\")\n","plt.show()\n","\n","# Strongest correlations\n","print(\"\\nüìå Top 5 Positive & Negative Correlations:\")\n","corr_unstacked = corr.unstack().sort_values(ascending=False)\n","corr_unstacked = corr_unstacked[corr_unstacked < 0.999]  # remove self-correlations\n","display(pd.concat([\n","    corr_unstacked.head(5).to_frame(\"Top Positive Correlations\"),\n","    corr_unstacked.tail(5).to_frame(\"Top Negative Correlations\")\n","], axis=1))\n","\n","# ----------------------------------------------------------\n","# 4Ô∏è‚É£ Demographic & Risk Factor Relationships\n","# ----------------------------------------------------------\n","# Gender-wise eligibility\n","sns.barplot(x='gender', y='emi_eligibility', data=df, estimator=lambda x: np.mean(x=='Yes')*100)\n","plt.title(\"Gender vs EMI Eligibility (%)\")\n","plt.ylabel(\"Approval Rate (%)\")\n","plt.show()\n","\n","# Education level influence\n","sns.barplot(x='education', y='emi_eligibility', data=df, estimator=lambda x: np.mean(x=='Yes')*100)\n","plt.title(\"Education Level vs EMI Eligibility (%)\")\n","plt.ylabel(\"Approval Rate (%)\")\n","plt.xticks(rotation=45)\n","plt.show()\n","\n","# House type & EMI risk\n","sns.barplot(x='house_type', y='emi_eligibility', data=df, estimator=lambda x: np.mean(x=='Yes')*100)\n","plt.title(\"House Type vs EMI Eligibility (%)\")\n","plt.ylabel(\"Approval Rate (%)\")\n","plt.show()\n","\n","# Age vs EMI eligibility trend\n","sns.histplot(data=df, x='age', hue='emi_eligibility', kde=True, bins=30, palette='coolwarm')\n","plt.title(\"Age Distribution by EMI Eligibility\")\n","plt.show()\n","\n","# ----------------------------------------------------------\n","# 5Ô∏è‚É£ Risk Feature Insights\n","# ----------------------------------------------------------\n","# Compare distributions for approved vs rejected\n","num_cols = ['monthly_salary','existing_loans','credit_score','bank_balance','emergency_fund']\n","\n","for col in num_cols:\n","    plt.figure(figsize=(8,4))\n","    sns.kdeplot(data=df, x=col, hue='emi_eligibility', fill=True)\n","    plt.title(f\"{col} Distribution by EMI Eligibility\")\n","    plt.show()\n","\n","# ----------------------------------------------------------\n","# 6Ô∏è‚É£ Business Insights Summary\n","# ----------------------------------------------------------\n","print(\"\\nüí° Business Insights:\")\n","\n","print(\"\"\"\n","1Ô∏è‚É£ Income and Loan Factors:\n","   ‚Ä¢ Applicants with higher monthly salary and lower existing loan amounts\n","     show higher EMI eligibility.\n","   ‚Ä¢ Strong positive correlation between monthly salary, bank balance,\n","     and max_monthly_emi indicates good repayment capacity.\n","\n","2Ô∏è‚É£ Credit & Risk:\n","   ‚Ä¢ Credit score and emergency fund both positively impact approval probability.\n","   ‚Ä¢ Applicants with poor credit or low savings face rejection risk.\n","\n","3Ô∏è‚É£ Demographics:\n","   ‚Ä¢ Married and educated individuals tend to have higher approval rates.\n","   ‚Ä¢ Younger age groups (<25) show lower eligibility due to limited employment years.\n","\n","4Ô∏è‚É£ Housing:\n","   ‚Ä¢ Those with 'Own' or 'Family' housing often get approved ‚Äî lower financial stress from rent.\n","   ‚Ä¢ 'Rented' applicants show higher rejection correlation due to added monthly liabilities.\n","\n","5Ô∏è‚É£ Lending Scenarios:\n","   ‚Ä¢ Certain EMI scenarios may have stricter credit thresholds; visualize their\n","     approval rates for portfolio optimization.\n","\"\"\")\n"],"metadata":{"id":"4EasoHq_agLp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","df['monthly_rent'].hist(bins=50)\n","plt.xlabel('Monthly Rent')\n","plt.ylabel('Count')\n","plt.show()\n"],"metadata":{"id":"5PsRvWTAxefG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.credit_score.describe()"],"metadata":{"id":"_C4938odlXaw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.nunique()"],"metadata":{"id":"fgB11OlQxWiA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 3: Feature Engineering\n","\n","* Create derived financial ratios (debt-to-income, expense-to-income, affordability ratios)\n","* Generate risk scoring features based on credit history and employment stability\n","* Apply categorical encoding and numerical feature scaling\n","* Develop interaction features between key financial variables\n"],"metadata":{"id":"sFoqC50c1Bu7"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"qbet1HwdGDTz"}},{"cell_type":"code","source":["# ----------------------------------------------------------\n","# ‚öôÔ∏è Step 3: Feature Engineering\n","# ----------------------------------------------------------\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","# Make a working copy\n","fe = df.copy()\n","\n","# ----------------------------------------------------------\n","# 1Ô∏è‚É£ Derived Financial Ratios\n","# ----------------------------------------------------------\n","# To avoid division errors, add small epsilon (1e-6)\n","eps = 1e-6\n","\n","# Total monthly expenses (combine major cost components)\n","fe['total_expenses'] = (\n","    fe['monthly_rent'].fillna(0) +\n","    fe['school_fees'].fillna(0) +\n","    fe['college_fees'].fillna(0) +\n","    fe['travel_expenses'].fillna(0) +\n","    fe['groceries_utilities'].fillna(0) +\n","    fe['other_monthly_expenses'].fillna(0) +\n","    fe['current_emi_amount'].fillna(0)\n",")\n","\n","# Debt-to-Income Ratio\n","fe['debt_to_income'] = fe['existing_loans'] / (fe['monthly_salary'] + eps)\n","\n","# Expense-to-Income Ratio\n","fe['expense_to_income'] = fe['total_expenses'] / (fe['monthly_salary'] + eps)\n","\n","# EMI Affordability Ratio ‚Äî how much of income can safely go toward EMI\n","fe['estimated_affordability_ratio'] = (\n","    (fe['monthly_salary'] - fe['other_monthly_expenses']) /\n","    (fe['requested_amount'] / fe['requested_tenure'] + eps)\n",")\n","\n","# Savings Ratio ‚Äî shows liquidity safety\n","fe['savings_ratio'] = (fe['bank_balance'] + fe['emergency_fund']) / (fe['monthly_salary'] + eps)\n","\n","# ----------------------------------------------------------\n","# 2Ô∏è‚É£ Risk Scoring Features\n","# ----------------------------------------------------------\n","\n","# Credit Score Risk Bucket\n","def credit_risk(score):\n","    if pd.isna(score):\n","        return 'Unknown'\n","    elif score >= 800:\n","        return 'Very Low Risk'\n","    elif score >= 700:\n","        return 'Low Risk'\n","    elif score >= 600:\n","        return 'Medium Risk'\n","    elif score >= 500:\n","        return 'High Risk'\n","    else:\n","        return 'Very High Risk'\n","\n","fe['credit_risk_level'] = fe['credit_score'].apply(credit_risk)\n","\n","# Employment Stability ‚Äî years of employment bucket\n","def employment_stability(years):\n","    if years >= 5: return 'Stable'\n","    elif years >= 2: return 'Moderate'\n","    else: return 'Unstable'\n","\n","fe['employment_stability'] = fe['years_of_employment'].apply(employment_stability)\n","\n","# Combined risk score (numerical)\n","risk_map = {\n","    'Very Low Risk': 1,\n","    'Low Risk': 2,\n","    'Medium Risk': 3,\n","    'High Risk': 4,\n","    'Very High Risk': 5,\n","    'Unknown': np.nan\n","}\n","stability_map = {'Stable': 1, 'Moderate': 2, 'Unstable': 3}\n","\n","fe['combined_risk_score'] = (\n","    fe['credit_risk_level'].map(risk_map) +\n","    fe['employment_stability'].map(stability_map)\n",")\n","# ----------------------------------------------------------\n","# 4. Interaction Features\n","# ----------------------------------------------------------\n","# Income √ó Credit ‚Üí Financial Strength\n","fe['income_credit_interaction'] = fe['monthly_salary'] * fe['credit_score']\n","\n","# Employment √ó Income ‚Üí Stability value\n","fe['employment_income_interaction'] = fe['years_of_employment'] * fe['monthly_salary']\n","\n","# Expense √ó Loan ‚Üí Pressure factor\n","fe['expense_loan_interaction'] = fe['total_expenses'] * fe['existing_loans']\n","\n","# ----------------------------------------------------------\n","# ‚úÖ Final Check\n","# ----------------------------------------------------------\n","print(\"\\n‚úÖ Feature Engineering Completed Successfully!\")\n","print(f\"Total Features: {fe.shape[1]}\")\n","\n","display(fe.head())\n","\n","# Optional: show correlation heatmap of new engineered features\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","engineered_cols = [\n","    'debt_to_income','expense_to_income','estimated_affordability_ratio',\n","    'savings_ratio','combined_risk_score','income_credit_interaction',\n","    'employment_income_interaction','expense_loan_interaction'\n","]\n","\n","plt.figure(figsize=(10,6))\n","sns.heatmap(fe[engineered_cols].corr(), annot=True, cmap='Blues', fmt=\".2f\")\n","plt.title(\"üìä Correlation Among Engineered Features\")\n","plt.show()\n"],"metadata":{"id":"ECHcbQYqthJ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mRA5wEFZ0Qgn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# # ----------------------------------------------------------\n","# # 3Ô∏è‚É£ Categorical Encoding\n","# # ----------------------------------------------------------\n","# cat_cols = [\n","#     'gender', 'marital_status', 'education', 'employment_type',\n","#     'company_type', 'house_type', 'emi_scenario',\n","#     'credit_risk_level', 'employment_stability'\n","# ]\n","\n","# # Label Encoding (simple, efficient for ML models)\n","# encoder = LabelEncoder()\n","# for col in cat_cols:\n","#     fe[col] = encoder.fit_transform(fe[col].astype(str))\n","\n","# # ----------------------------------------------------------\n","# # 4Ô∏è‚É£ Numerical Feature Scaling\n","# # ----------------------------------------------------------\n","# num_cols = [\n","#     'age', 'monthly_salary', 'monthly_rent', 'years_of_employment', 'family_size',\n","#     'dependents', 'school_fees', 'college_fees', 'travel_expenses',\n","#     'groceries_utilities', 'other_monthly_expenses', 'existing_loans',\n","#     'current_emi_amount', 'credit_score', 'bank_balance', 'emergency_fund',\n","#     'requested_amount', 'requested_tenure', 'max_monthly_emi',\n","#     'debt_to_income', 'expense_to_income', 'estimated_affordability_ratio',\n","#     'savings_ratio', 'combined_risk_score'\n","# ]\n","\n","# scaler = StandardScaler()\n","# fe[num_cols] = scaler.fit_transform(fe[num_cols])\n","\n"],"metadata":{"id":"E7fhesHezzyy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  **Catogorical encoding and Scaling processes.."],"metadata":{"id":"adtRGipDOnYT"}},{"cell_type":"code","source":["fe.columns"],"metadata":{"id":"59LH0NGzP6_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zFDmBdLoQ7wb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#OneHotEncoding fetures (Nominal features):-\n","OneHot_enc_cols = [\n","     'gender', 'marital_status', 'education',\n","       'employment_type', 'company_type', 'house_type',\n","       'emi_scenario',\n","       'credit_risk_level', 'employment_stability'\n"," ]\n","\n","numerical_cols=[\n","    'monthly_salary', 'monthly_rent', 'school_fees', 'college_fees',\n","    'travel_expenses', 'groceries_utilities', 'other_monthly_expenses',\n","    'existing_loans', 'current_emi_amount', 'bank_balance',\n","    'emergency_fund', 'requested_amount', 'requested_tenure',\n","    'total_expenses', 'debt_to_income', 'expense_to_income',\n","    'estimated_affordability_ratio', 'savings_ratio',\n","    'combined_risk_score', 'income_credit_interaction',\n","    'employment_income_interaction', 'expense_loan_interaction'\n","]\n"],"metadata":{"id":"NQdelFFiO7yr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"65iP9pzmuwQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vseYnH2Aurq7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jxYEahsslFxD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pbK7t1RvlqwK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lM23VG8qmQVb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"03JP9YlBlyV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# OneHot Encoding\n","from sklearn.preprocessing import OneHotEncoder\n","\n","enocder=OneHotEncoder()\n","encoded_cat_df=pd.DataFrame(enocder.fit_transform(fe[OneHot_enc_cols]).toarray(),\n","                            columns=enocder.get_feature_names_out(),\n","                            index=fe.index)\n","\n","encoded_df = pd.concat(\n","    [fe.drop(columns=OneHot_enc_cols, axis=1), encoded_cat_df],\n","    axis=1\n",")\n"],"metadata":{"id":"UiX6GwTPSFgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(fe.index.equals(encoded_cat_df.index))\n"],"metadata":{"id":"3bo5NIaOnIrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scaling\n","\n","temp=encoded_df.copy()\n","from sklearn.preprocessing import StandardScaler\n","scaler=StandardScaler()\n","encoded_df[numerical_cols]=scaler.fit_transform(encoded_df[numerical_cols])"],"metadata":{"id":"Tf5VKgzHVxCT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Storing scaler\n","import joblib,os\n","\n","joblib.dump(scaler,os.path.join('/content/drive/MyDrive/Labmentix intern projects/EMIPredict AI /Models/Scalers & Encoders','scaler.joblib'))"],"metadata":{"id":"STeJiBPPVSj3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Storing Encoder\n","joblib.dump(enocder,os.path.join('/content/drive/MyDrive/Labmentix intern projects/EMIPredict AI /Models/Scalers & Encoders','encoder.joblib'))"],"metadata":{"id":"3U6FTgsKp4oy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_df.isna().sum()"],"metadata":{"id":"BFYZL-x8js1A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"r7Wh4hLUUYgs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ** Spliting of dataset (Tringing testing and Validation..)"],"metadata":{"id":"M8IWE4Ngnt35"}},{"cell_type":"markdown","source":["*** For classification predictions...(Multiclass classification)\n","\n","* input Columns(features):-['age', 'monthly_salary', 'years_of_employment',\n","       'monthly_rent',\n","       'family_size', 'dependents', 'school_fees', 'college_fees',\n","       'travel_expenses', 'groceries_utilities', 'other_monthly_expenses',\n","       'existing_loans', 'current_emi_amount', 'credit_score', 'bank_balance',\n","       'emergency_fund', 'requested_amount', 'requested_tenure' 'total_expenses',\n","       'debt_to_income', 'expense_to_income', 'estimated_affordability_ratio',\n","       'savings_ratio', 'combined_risk_score', 'income_credit_interaction',\n","       'employment_income_interaction', 'expense_loan_interaction',\n","       'gender_Female', 'gender_Male', 'marital_status_Married',\n","       'marital_status_Single', 'education_Graduate', 'education_High School',\n","       'education_Post Graduate', 'education_Professional',\n","       'employment_type_Government', 'employment_type_Private',\n","       'employment_type_Self-employed', 'company_type_Large Indian',\n","       'company_type_MNC', 'company_type_Mid-size', 'company_type_Small',\n","       'company_type_Startup', 'house_type_Family', 'house_type_Own',\n","       'house_type_Rented', 'emi_scenario_E-commerce Shopping EMI',\n","       'emi_scenario_Education EMI', 'emi_scenario_Home Appliances EMI',\n","       'emi_scenario_Personal Loan EMI', 'emi_scenario_Vehicle EMI',\n","       'credit_risk_level_High Risk', 'credit_risk_level_Low Risk',\n","       'credit_risk_level_Medium Risk', 'credit_risk_level_Very High Risk',\n","       'credit_risk_level_Very Low Risk', 'employment_stability_Moderate',\n","       'employment_stability_Stable', 'employment_stability_Unstable']\n","\n","  * target feature:-emi_eligibility ('Not_Eligible':-(1), 'Eligible':-(2), 'High_Risk':-(3))"],"metadata":{"id":"BYLVg0zgn-e2"}},{"cell_type":"code","source":[],"metadata":{"id":"5Pp_Wfirn7Mp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","## maping classification targets..\n","encoded_df['emi_eligibility_target']=encoded_df['emi_eligibility'].map({\n","    'Not_Eligible': 0,\n","    'Eligible': 1,\n","    'High_Risk': 2\n","})"],"metadata":{"id":"rt-ZNwYRs8al"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## shuffling of data\n","encoded_df= encoded_df.sample(frac=1)"],"metadata":{"id":"nUgAtE6Y0EOn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I-ELPAlT1DA1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Data spilting..\n","from sklearn.model_selection import train_test_split\n","X=encoded_df.drop(columns=['max_monthly_emi','emi_eligibility_target','emi_eligibility'],axis=1)\n","y_clf=encoded_df['emi_eligibility_target']\n","y_rg=encoded_df['max_monthly_emi']\n"],"metadata":{"id":"6y5NE4PPtOtn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train_clf,x_temp,y_train_clf,y_temp=train_test_split(X,y_clf,test_size=0.2,random_state=42)\n","x_val_clf,x_test_clf,y_val_clf,y_test_clf=train_test_split(x_temp,y_temp,test_size=0.5,random_state=42)\n","\n","x_train_rg,x_temp,y_train_rg,y_temp = train_test_split(X,y_rg,test_size=0.2,random_state=42)\n","x_val_rg,x_test_rg,y_val_rg,y_test_rg=train_test_split(x_temp,y_temp,test_size=0.5,random_state=42)\n","\n"],"metadata":{"id":"24GvCWwkuog0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_train_clf.shape,x_val_clf.shape,x_test_clf.shape)\n","print(x_train_rg.shape,x_val_rg.shape,x_test_rg.shape)\n","\n","print(y_train_clf.shape,y_val_clf.shape,y_test_clf.shape)\n","print(y_train_rg.shape,y_val_rg.shape,y_test_rg.shape )\n"],"metadata":{"id":"sPfeJSdoxksM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train_clf.columns"],"metadata":{"id":"ihNVJMeS1VEG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4_5XH1Iv1StW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ***7. ML Model Implementation***"],"metadata":{"id":"VfCC591jGiD4"}},{"cell_type":"markdown","source":["A. Classification Models (EMI Eligibility Prediction)\n","Required Models (Minimum 3):\n","\n","* Logistic Regression - Baseline interpretable model\n","* Random Forest Classifier - Feature importance analysis\n","* XGBoost Classifier - High-performance gradient boosting\n","\n","Additional Models (Choose 1+):\n","\n","* Support Vector Classifier (SVC)\n","* Decision Tree Classifier\n","* Gradient Boosting Classifier\n","* LightGBM Classifier\n","* CatBoost Classifier"],"metadata":{"id":"cW1GHm_2thq1"}},{"cell_type":"code","source":["## Importing Required Libraries..\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from xgboost import XGBClassifier\n","from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n","                             f1_score, roc_auc_score, confusion_matrix,\n","                             classification_report, roc_curve)\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"],"metadata":{"id":"L8tdeMfWt4zu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ** Setup for Mlflow using DagsHUb"],"metadata":{"id":"P2I_eysHajkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mlflow"],"metadata":{"id":"fYnMQFoOzaq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import mlflow\n","import mlflow.sklearn"],"metadata":{"id":"nSfrY8eczfDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install -q dagshub 'mlflow>=2,<3'\n"],"metadata":{"id":"GZhs4r0MU0Gv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import dagshub\n","dagshub.init(repo_owner='chandrapapr1501', repo_name='MLflow-model-tracking', mlflow=True)"],"metadata":{"id":"TsB6NVk5d6HF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","mlflow.set_tracking_uri(f\"https://dagshub.com/chandrapapr1501/MLflow-model-tracking.mlflow/\")\n","mlflow.set_experiment(\"colab_experiment3\")\n"],"metadata":{"id":"66_7Rm-oZPT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import mlflow\n","with mlflow.start_run():\n","  # Your training code here...\n","  mlflow.log_metric('accuracy', 42)\n","  mlflow.log_param('Param name', 'Value')"],"metadata":{"id":"2pdT-yg4d3qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2 exp..\n","mlflow.set_experiment(\"colab_experiment1\")\n","\n","with mlflow.start_run():\n","  # Your training code here...\n","  mlflow.log_metric('accuracy', 99.99)\n","  mlflow.log_param('Param name', 'Value')"],"metadata":{"id":"Tc2lYveHlMP1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(mlflow.__version__)"],"metadata":{"id":"_51S4NeIFSzC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import mlflow\n","import mlflow.sklearn\n","from mlflow.models import infer_signature\n","import os\n","\n","# 1. Setup MLflow\n","def setup_mlflow(experiment_name=\"EMI_Prediction_Models\"):\n","    \"\"\"\n","    Configure MLflow tracking\n","    \"\"\"\n","    # Set tracking URI (local or remote server)\n","    # mlflow.set_tracking_uri(\"file:./mlruns\")  # Local tracking\n","    # For remote: mlflow.set_tracking_uri(\"http://localhost:5000\")\n","\n","    # Create or get experiment\n","    try:\n","        experiment_id = mlflow.create_experiment(experiment_name)\n","        print(f\"MLflow experiment '{experiment_name}' created with ID: {experiment_id}\")\n","    except Exception as e:\n","        print(f\"Error creating experiment '{experiment_name}': {e}\")\n","        print(f\"Attempting to get existing experiment '{experiment_name}'\")\n","        try:\n","            experiment = mlflow.get_experiment_by_name(experiment_name)\n","            experiment_id = experiment.experiment_id\n","            print(f\"MLflow experiment '{experiment_name}' already exists with ID: {experiment_id}\")\n","        except Exception as e:\n","            print(f\"Error getting experiment '{experiment_name}': {e}\")\n","            raise # Re-raise if getting also fails\n","\n","\n","    mlflow.set_experiment(experiment_name)\n","    print(f\"MLflow experiment '{experiment_name}' is ready!\")\n","\n","    return experiment_id"],"metadata":{"id":"IbkUifHlzPgD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","import os\n","\n","base_path = \"/content/drive/MyDrive/Labmentix intern projects/EMIPredict AI /Models\"\n","clf_models_path = os.path.join(base_path, \"clf_models\")\n","reg_models_path = os.path.join(base_path, \"reg_models\")\n","\n","os.makedirs(clf_models_path, exist_ok=True)\n","os.makedirs(reg_models_path, exist_ok=True)\n","\n","print(f\"Created directory: {clf_models_path}\")\n","print(f\"Created directory: {reg_models_path}\")"],"metadata":{"id":"9SSz1ktwoD_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_clf.value_counts()"],"metadata":{"id":"VWimS-fToU27"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Model Training Function\n","def train_classification_models(X_train, X_test, y_train, y_test, experiment_name=\"EMI_Eligibility_prediction\"):\n","    \"\"\"\n","    Train classification models and log to MLflow\n","    \"\"\"\n","    setup_mlflow(experiment_name=experiment_name)\n","\n","    # 'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n","    # 'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n","    models = {\n","        # 'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'),\n","        # 'Decision Tree': DecisionTreeClassifier(random_state=42),\n","        'SVC': SVC(probability=True, random_state=42),\n","        'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n","    }\n","\n","    results = {}\n","\n","    for name, model in models.items():\n","        with mlflow.start_run(run_name=f\"Classification_{name}\"):\n","            print(f\"\\nTraining {name}...\")\n","\n","            mlflow.log_param(\"model_type\", \"classification\")\n","            mlflow.log_param(\"algorithm\", name)\n","\n","            # Train model\n","            model.fit(X_train, y_train)\n","\n","            # Predictions\n","            y_pred = model.predict(X_test)\n","            # For multi-class, predict_proba returns probabilities for each class.\n","            # roc_auc_score for multi-class needs probabilities for each class or a single probability for one class in binary case.\n","            # Since we have 3 classes, we need to specify multi_class.\n","            y_pred_proba = model.predict_proba(X_test)\n","\n","            # Evaluation metrics\n","            metrics = {\n","                'accuracy': accuracy_score(y_test, y_pred),\n","                'precision': precision_score(y_test, y_pred, average='weighted'),\n","                'recall': recall_score(y_test, y_pred, average='weighted'),\n","                'f1_score': f1_score(y_test, y_pred, average='weighted'),\n","                'roc_auc': roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n","            }\n","\n","            # Cross-validation score\n","            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n","            metrics['cv_mean'] = cv_scores.mean()\n","            metrics['cv_std'] = cv_scores.std()\n","\n","            # Log metrics\n","            mlflow.log_metrics(metrics)\n","\n","            # Create and log confusion matrix\n","            cm = confusion_matrix(y_test, y_pred)\n","            fig, ax = plt.subplots(figsize=(8, 6))\n","            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n","            ax.set_title(f'Confusion Matrix - {name}')\n","            ax.set_ylabel('Actual')\n","            ax.set_xlabel('Predicted')\n","            plt.tight_layout()\n","            mlflow.log_figure(fig, f\"confusion_matrix_{name}.png\")\n","            plt.close()\n","\n","            # Create and log ROC curve\n","            # For multi-class, ROC curve needs to be plotted per class or using micro/macro averaging.\n","            # Here, we'll skip plotting a single ROC curve as it's less informative for multi-class without averaging.\n","            # If needed, we can add plotting logic for multi-class ROC.\n","            # fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","            # fig, ax = plt.subplots(figsize=(8, 6))\n","            # ax.plot(fpr, tpr, label=f'AUC = {metrics[\"roc_auc\"]:.3f}')\n","            # ax.plot([0, 1], [0, 1], 'k--', label='Random')\n","            # ax.set_xlabel('False Positive Rate')\n","            # ax.set_ylabel('True Positive Rate')\n","            # ax.set_title(f'ROC Curve - {name}')\n","            # ax.legend()\n","            # plt.tight_layout()\n","            # mlflow.log_figure(fig, f\"roc_curve_{name}.png\")\n","            # plt.close()\n","\n","          # Log feature importance (if available)\n","            if hasattr(model, 'feature_importances_'):\n","                feature_names = X_train.columns.tolist()\n","                importance_df = pd.DataFrame({\n","                    'feature': feature_names,\n","                    'importance': model.feature_importances_\n","                }).sort_values('importance', ascending=False)\n","\n","                fig, ax = plt.subplots(figsize=(10, 6))\n","                importance_df.head(20).plot(x='feature', y='importance',\n","                                            kind='barh', ax=ax)\n","                ax.set_title(f'Top 20 Feature Importances - {name}')\n","                plt.tight_layout()\n","                mlflow.log_figure(fig, f\"feature_importance_{name}.png\")\n","                plt.close()\n","\n","                # Log as artifact\n","                importance_df.to_csv(f\"feature_importance_{name}.csv\", index=False)\n","                mlflow.log_artifact(f\"feature_importance_{name}.csv\")\n","\n","            # Infer signature\n","            signature = infer_signature(X_train, model.predict(X_train))\n","\n","            #Saving model locally\n","            joblib.dump(model, os.path.join(clf_models_path, f\"{name}.joblib\"))\n","\n","            # # Log model\n","            # mlflow.sklearn.log_model(\n","            #     model,\n","            #     artifact_path=\"model\",\n","            #     signature=signature,\n","            #     registered_model_name=f\"EMI_Classification_{name}\"\n","            # )\n","\n","            # Log classification report\n","            report = classification_report(y_test, y_pred, output_dict=True)\n","            report_df = pd.DataFrame(report).transpose()\n","            report_df.to_csv(f\"classification_report_{name}.csv\")\n","            mlflow.log_artifact(f\"classification_report_{name}.csv\")\n","\n","            results[name] = {\n","                'model': model,\n","                'metrics': metrics,\n","                'predictions': y_pred,\n","                'probabilities': y_pred_proba,\n","                'run_id': mlflow.active_run().info.run_id\n","\n","            }\n","\n","            print(f\"‚úì Model logged successfully!\")\n","            print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n","            print(f\"ROC-AUC: {metrics['roc_auc']:.4f}\")\n","\n","    return results"],"metadata":{"id":"saT6dzJevhOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ae49a780"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 3. Model Evaluation and Visualization\n","def evaluate_classification_models(results, y_test):\n","    \"\"\"\n","    Comprehensive evaluation and visualization\n","    \"\"\"\n","    # Create comparison DataFrame\n","    comparison_data = []\n","    for name, result in results.items():\n","        metrics = result['metrics']\n","        comparison_data.append({\n","            'Model': name,\n","            'Accuracy': metrics['accuracy'],\n","            'Precision': metrics['precision'],\n","            'Recall': metrics['recall'],\n","            'F1-Score': metrics['f1_score'],\n","            'ROC-AUC': metrics['roc_auc'],\n","            'CV Mean': metrics['cv_mean'],\n","            'CV Std': metrics['cv_std']\n","        })\n","\n","    comparison_df = pd.DataFrame(comparison_data)\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"MODEL COMPARISON\")\n","    print(\"=\"*80)\n","    print(comparison_df.to_string(index=False))\n","\n","    # Visualizations\n","    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n","\n","    # 1. Metrics Comparison\n","    metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n","    comparison_df.set_index('Model')[metrics_to_plot].plot(kind='bar', ax=axes[0, 0])\n","    axes[0, 0].set_title('Model Performance Comparison')\n","    axes[0, 0].set_ylabel('Score')\n","    axes[0, 0].legend(loc='lower right')\n","    axes[0, 0].set_ylim([0, 1])\n","\n","    # 2. ROC Curves\n","    for name, result in results.items():\n","        fpr, tpr, _ = roc_curve(y_test, result['probabilities'])\n","        axes[0, 1].plot(fpr, tpr, label=f\"{name} (AUC={result['metrics']['roc_auc']:.3f})\")\n","    axes[0, 1].plot([0, 1], [0, 1], 'k--', label='Random')\n","    axes[0, 1].set_xlabel('False Positive Rate')\n","    axes[0, 1].set_ylabel('True Positive Rate')\n","    axes[0, 1].set_title('ROC Curves Comparison')\n","    axes[0, 1].legend()\n","\n","    # 3. Feature Importance (Random Forest)\n","    if 'Random Forest' in results:\n","        rf_model = results['Random Forest']['model']\n","        importances = rf_model.feature_importances_\n","        indices = np.argsort(importances)[-10:]  # Top 10 features\n","        axes[1, 0].barh(range(len(indices)), importances[indices])\n","        axes[1, 0].set_yticks(range(len(indices)))\n","        axes[1, 0].set_yticklabels([f'Feature {i}' for i in indices])\n","        axes[1, 0].set_xlabel('Importance')\n","        axes[1, 0].set_title('Top 10 Feature Importances (Random Forest)')\n","\n","    # 4. Confusion Matrix (Best Model)\n","    best_model_name = comparison_df.loc[comparison_df['ROC-AUC'].idxmax(), 'Model']\n","    cm = confusion_matrix(y_test, results[best_model_name]['predictions'])\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1])\n","    axes[1, 1].set_title(f'Confusion Matrix - {best_model_name}')\n","    axes[1, 1].set_ylabel('Actual')\n","    axes[1, 1].set_xlabel('Predicted')\n","\n","    plt.tight_layout()\n","    plt.savefig('classification_model_comparison.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","    return comparison_df"],"metadata":{"id":"I1sVZrkyvqcV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["B. Classification Models with MLflow (hyperparemeteric tuning)"],"metadata":{"id":"rI2sXrkS3cRT"}},{"cell_type":"code","source":["def train_and_log_classification_models(X_train, X_test, y_train, y_test,\n","                                       feature_names, experiment_name=\"hyperpara-Tuned_EMI_eligibility_prediction\"):\n","    \"\"\"\n","    Train classification models and log to MLflow\n","    \"\"\"\n","    setup_mlflow(experiment_name=\"hyperpara-Tuned_EMI_eligibility_prediction\")\n","\n","    models = {\n","        # 'Logistic_Regression': {\n","        #     'model': LogisticRegression(random_state=42, max_iter=1000,C=1.0,penalty='l2',solver='lbfgs'),\n","        #     'params': {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n","        # },\n","        # 'Random_Forest': {\n","        #     'model': RandomForestClassifier(n_estimators=100, random_state=42,\n","        #                                    max_depth=10, min_samples_split=5,criterion='gini'),\n","        #     'params': {'n_estimators': 100, 'max_depth': 10,\n","        #               'min_samples_split': 5, 'criterion': 'gini'}\n","        # },\n","        # 'XGBoost': {\n","        #     'model': XGBClassifier(random_state=42, n_estimators=100,\n","        #                           learning_rate=0.1, max_depth=6,eval_metric= 'logloss'),\n","        #     'params': {'n_estimators': 100, 'learning_rate': 0.1,\n","        #               'max_depth': 6, 'eval_metric': 'logloss'}\n","        # },\n","        'SVC': {\n","            'model': SVC(probability=True, random_state=42, C=1.0, kernel='rbf',gamma='scale'),\n","            'params': {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale'}\n","        }\n","        # 'Gradient_Boosting': {\n","        #     'model': GradientBoostingClassifier(random_state=42, n_estimators=100,learning_rate= 0.1,max_depth= 3),\n","        #     'params': {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3}\n","        # }\n","    }\n","\n","    results = {}\n","\n","    for name, model_info in models.items():\n","        with mlflow.start_run(run_name=f\"Classification_{name}\"):\n","            print(f\"\\n{'='*60}\")\n","            print(f\"Training and logging: {name}\")\n","            print(f\"{'='*60}\")\n","\n","            model = model_info['model']\n","            params = model_info['params']\n","\n","            # Log parameters\n","            mlflow.log_params(params)\n","            mlflow.log_param(\"model_type\", \"classification\")\n","            mlflow.log_param(\"algorithm\", name)\n","\n","            # Train model\n","            model.fit(X_train, y_train)\n","\n","            # Predictions\n","            y_pred = model.predict(X_test)\n","            y_pred_proba = model.predict_proba(X_test)\n","\n","            # Calculate metrics\n","            metrics = {\n","                'accuracy': accuracy_score(y_test, y_pred),\n","                'precision': precision_score(y_test, y_pred, average='weighted'),\n","                'recall': recall_score(y_test, y_pred, average='weighted'),\n","                'f1_score': f1_score(y_test, y_pred, average='weighted'),\n","                'roc_auc': roc_auc_score(y_test, y_pred_proba,multi_class='ovr')\n","            }\n","\n","            # Cross-validation\n","            cv_scores = cross_val_score(model, X_train, y_train, cv=5,\n","                                       scoring='accuracy')\n","            metrics['cv_accuracy_mean'] = cv_scores.mean()\n","            metrics['cv_accuracy_std'] = cv_scores.std()\n","\n","            # Log metrics\n","            mlflow.log_metrics(metrics)\n","\n","            # Create and log confusion matrix\n","            cm = confusion_matrix(y_test, y_pred)\n","            fig, ax = plt.subplots(figsize=(8, 6))\n","            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n","            ax.set_title(f'Confusion Matrix - {name}')\n","            ax.set_ylabel('Actual')\n","            ax.set_xlabel('Predicted')\n","            plt.tight_layout()\n","            mlflow.log_figure(fig, f\"confusion_matrix_{name}.png\")\n","            plt.close()\n","\n","            # Create and log ROC curve\n","            # fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","            # fig, ax = plt.subplots(figsize=(8, 6))\n","            # ax.plot(fpr, tpr, label=f'AUC = {metrics[\"roc_auc\"]:.3f}')\n","            # ax.plot([0, 1], [0, 1], 'k--', label='Random')\n","            # ax.set_xlabel('False Positive Rate')\n","            # ax.set_ylabel('True Positive Rate')\n","            # ax.set_title(f'ROC Curve - {name}')\n","            # ax.legend()\n","            # plt.tight_layout()\n","            # mlflow.log_figure(fig, f\"roc_curve_{name}.png\")\n","            # plt.close()\n","\n","            # Log feature importance (if available)\n","            if hasattr(model, 'feature_importances_'):\n","                importance_df = pd.DataFrame({\n","                    'feature': feature_names,\n","                    'importance': model.feature_importances_\n","                }).sort_values('importance', ascending=False)\n","\n","                fig, ax = plt.subplots(figsize=(10, 6))\n","                importance_df.head(15).plot(x='feature', y='importance',\n","                                           kind='barh', ax=ax)\n","                ax.set_title(f'Top 15 Feature Importances - {name}')\n","                plt.tight_layout()\n","                mlflow.log_figure(fig, f\"feature_importance_{name}.png\")\n","                plt.close()\n","\n","                # Log as artifact\n","                importance_df.to_csv(f\"feature_importance_{name}.csv\", index=False)\n","                mlflow.log_artifact(f\"feature_importance_{name}.csv\")\n","\n","            # Infer signature\n","            signature = infer_signature(X_train, model.predict(X_train))\n","\n","            #Saving model locally\n","            joblib.dump(model, os.path.join(clf_models_path, f\"{name}_tuned.joblib\"))\n","\n","            # Log model\n","            # mlflow.sklearn.log_model(\n","            #     model,\n","            #     artifact_path=\"model\",\n","            #     signature=signature,\n","            #     registered_model_name=f\"EMI_Eligibility_Classification_{name}\"\n","            # )\n","\n","            # Log classification report\n","            report = classification_report(y_test, y_pred, output_dict=True)\n","            report_df = pd.DataFrame(report).transpose()\n","            report_df.to_csv(f\"classification_report_{name}.csv\")\n","            mlflow.log_artifact(f\"classification_report_{name}.csv\")\n","\n","            # Store results\n","            results[name] = {\n","                'model': model,\n","                'metrics': metrics,\n","                'run_id': mlflow.active_run().info.run_id\n","            }\n","\n","            print(f\"‚úì Model logged successfully!\")\n","            print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n","            print(f\"  ROC-AUC: {metrics['roc_auc']:.4f}\")\n","\n","    return results"],"metadata":{"id":"iazZfeYV3YSJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression, Ridge\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from xgboost import XGBRegressor\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor"],"metadata":{"id":"g4nnrtMEubIg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report"],"metadata":{"id":"1hq_URLwvWmO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Model Training Function\n","def train_regression_models(X_train, X_test, y_train, y_test):\n","  \"\"\"\n","  Train regression models and log to MLflow\n","  \"\"\"\n","  setup_mlflow(experiment_name='Max_EMI_Prediction')\n","\n","  models = {\n","  # 'Linear Regression': LinearRegression(),\n","  'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n","  'XGBoost': XGBRegressor(random_state=42),\n","  'Decision Tree': DecisionTreeRegressor(random_state=42),\n","  'SVR': SVR(kernel='rbf'),\n","  'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n","\n","  }\n","\n","  results = {}\n","\n","  for name, model in models.items():\n","    with mlflow.start_run(run_name=f\"Regression_{name}\"):\n","      print(f\"\\nTraining {name}...\")\n","\n","\n","      mlflow.log_param(\"model_type\", \"regression\")\n","      mlflow.log_param(\"algorithm\", name)\n","\n","      # Train model\n","      model.fit(X_train, y_train)\n","\n","      # Predictions\n","      y_pred_train = model.predict(X_train)\n","      y_pred_test = model.predict(X_test)\n","\n","      # Evaluation metrics\n","      metrics = {\n","          'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n","          'mae': mean_absolute_error(y_test, y_pred_test),\n","          'r2': r2_score(y_test, y_pred_test),\n","          'mape': mean_absolute_percentage_error(y_test, y_pred_test) * 100,\n","          'train_r2': r2_score(y_train, y_pred_train),\n","          'mse': mean_squared_error(y_test, y_pred_test)\n","\n","      }\n","\n","      # Cross-validation score\n","      cv_scores = cross_val_score(model, X_train, y_train, cv=5,\n","                                  scoring='neg_mean_squared_error')\n","      metrics['cv_rmse_mean'] = np.sqrt(cv_scores.mean())\n","      metrics['cv_rmse_std'] = np.sqrt(cv_scores.std())\n","\n","        # Log metrics\n","      mlflow.log_metrics(metrics)\n","\n","      # Create and log actual vs predicted plot\n","      fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n","\n","      # Actual vs Predicted\n","      axes[0].scatter(y_test, y_pred_test, alpha=0.5)\n","      axes[0].plot([y_test.min(), y_test.max()],\n","                  [y_test.min(), y_test.max()], 'r--', lw=2)\n","      axes[0].set_xlabel('Actual Values')\n","      axes[0].set_ylabel('Predicted Values')\n","      axes[0].set_title(f'Actual vs Predicted - {name}')\n","\n","      # Residuals\n","      residuals = y_test - y_pred_test\n","      axes[1].scatter(y_pred_test, residuals, alpha=0.5)\n","      axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n","      axes[1].set_xlabel('Predicted Values')\n","      axes[1].set_ylabel('Residuals')\n","      axes[1].set_title(f'Residual Plot - {name}')\n","\n","      plt.tight_layout()\n","      mlflow.log_figure(fig, f\"prediction_plots_{name}.png\")\n","      plt.close()\n","\n","      # Log feature importance (if available)\n","      if hasattr(model, 'feature_importances_'):\n","        feature_names = X_train.columns.tolist()\n","        importance_df = pd.DataFrame({\n","            'feature': feature_names,\n","            'importance': model.feature_importances_\n","        }).sort_values('importance', ascending=False)\n","\n","        fig, ax = plt.subplots(figsize=(10, 6))\n","        importance_df.head(20).plot(x='feature', y='importance',\n","                                    kind='barh', ax=ax)\n","        ax.set_title(f'Top 20 Feature Importances - {name}')\n","        plt.tight_layout()\n","        mlflow.log_figure(fig, f\"feature_importance_{name}.png\")\n","        plt.close()\n","\n","        importance_df.to_csv(f\"feature_importance_{name}.csv\", index=False)\n","        mlflow.log_artifact(f\"feature_importance_{name}.csv\")\n","\n","      # Infer signature\n","      signature = infer_signature(X_train, model.predict(X_train))\n","\n","      #Saving model locally\n","      joblib.dump(model, os.path.join(reg_models_path, f\"{name}.joblib\"))\n","\n","\n","      # Log model\n","      # mlflow.sklearn.log_model(\n","      #     model,\n","      #     artifact_path=\"model\",\n","      #     signature=signature,\n","      #     registered_model_name=f\"EMI_Regression_{name}\"\n","      # )\n","\n","      # Save prediction results\n","      results_df = pd.DataFrame({\n","          'Actual': y_test,\n","          'Predicted': y_pred_test,\n","          'Residual': residuals\n","      })\n","      results_df.to_csv(f\"predictions_{name}.csv\", index=False)\n","      mlflow.log_artifact(f\"predictions_{name}.csv\")\n","\n","      # Store results\n","      results[name] = {\n","          'model': model,\n","          'metrics': metrics,\n","          'run_id': mlflow.active_run().info.run_id\n","      }\n","\n","      print(f\"‚úì Model logged successfully!\")\n","      print(f\"  RMSE: {metrics['rmse']:.2f}\")\n","      print(f\"  R¬≤: {metrics['r2']:.4f}\")\n","  return results\n"],"metadata":{"id":"rJ92PEaq5kPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Model Evaluation and Visualization\n","def evaluate_regression_models(results, y_test):\n","    \"\"\"\n","    Comprehensive evaluation and visualization for regression\n","    \"\"\"\n","    # Create comparison DataFrame\n","    comparison_data = []\n","    for name, result in results.items():\n","        metrics = result['metrics']\n","        comparison_data.append({\n","            'Model': name,\n","            'RMSE': metrics['rmse'],\n","            'MAE': metrics['mae'],\n","            'R¬≤': metrics['r2'],\n","            'MAPE (%)': metrics['mape'],\n","            'Train R¬≤': metrics['train_r2'],\n","            'CV RMSE': metrics['cv_rmse_mean']\n","        })\n","\n","    comparison_df = pd.DataFrame(comparison_data)\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"REGRESSION MODEL COMPARISON\")\n","    print(\"=\"*80)\n","    print(comparison_df.to_string(index=False))\n","\n","    # Visualizations\n","    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n","\n","    # 1. Metrics Comparison\n","    comparison_df.set_index('Model')[['RMSE', 'MAE']].plot(kind='bar', ax=axes[0, 0])\n","    axes[0, 0].set_title('Error Metrics Comparison')\n","    axes[0, 0].set_ylabel('Error')\n","    axes[0, 0].legend()\n","\n","    # 2. R¬≤ Comparison\n","    comparison_df.set_index('Model')[['R¬≤', 'Train R¬≤']].plot(kind='bar', ax=axes[0, 1])\n","    axes[0, 1].set_title('R¬≤ Score Comparison')\n","    axes[0, 1].set_ylabel('R¬≤ Score')\n","    axes[0, 1].legend()\n","    axes[0, 1].set_ylim([0, 1])\n","\n","    # 3. Actual vs Predicted (Best Model)\n","    best_model_name = comparison_df.loc[comparison_df['R¬≤'].idxmax(), 'Model']\n","    best_predictions = results[best_model_name]['predictions']\n","    axes[1, 0].scatter(y_test, best_predictions, alpha=0.5)\n","    axes[1, 0].plot([y_test.min(), y_test.max()],\n","                    [y_test.min(), y_test.max()], 'r--', lw=2)\n","    axes[1, 0].set_xlabel('Actual Values')\n","    axes[1, 0].set_ylabel('Predicted Values')\n","    axes[1, 0].set_title(f'Actual vs Predicted - {best_model_name}')\n","\n","    # 4. Residuals Plot\n","    residuals = y_test - best_predictions\n","    axes[1, 1].scatter(best_predictions, residuals, alpha=0.5)\n","    axes[1, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n","    axes[1, 1].set_xlabel('Predicted Values')\n","    axes[1, 1].set_ylabel('Residuals')\n","    axes[1, 1].set_title(f'Residual Plot - {best_model_name}')\n","\n","    plt.tight_layout()\n","    plt.savefig('regression_model_comparison.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","    return comparison_df"],"metadata":{"id":"U_wMdEUk5pwD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Hyperparamatric Tuned Regression Models with MLflow"],"metadata":{"id":"RDMnyhsz84gX"}},{"cell_type":"code","source":["def train_and_log_regression_models(X_train, X_test, y_train, y_test,\n","                                   feature_names, experiment_name='Hyperpar_tuned_MAX_EMI_prediction'):\n","    \"\"\"\n","    Train regression models and log to MLflow\n","    \"\"\"\n","    setup_mlflow(experiment_name='Hyperpar_tuned_MAX_EMI_prediction')\n","\n","    models = {\n","        'Linear_Regression': {\n","            'model': LinearRegression(),\n","            'params': {'fit_intercept': True, 'normalize': False}\n","        },\n","        'Random_Forest': {\n","            'model': RandomForestRegressor(n_estimators=100, random_state=42,\n","                                          max_depth=10, min_samples_split=5),\n","            'params': {'n_estimators': 100, 'max_depth': 10,\n","                      'min_samples_split': 5}\n","        },\n","        'XGBoost': {\n","            'model': XGBRegressor(random_state=42, n_estimators=100,\n","                                 learning_rate=0.1, max_depth=6),\n","            'params': {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 6}\n","        },\n","        'Gradient_Boosting': {\n","            'model': GradientBoostingRegressor(random_state=42, n_estimators=100,max_depth=3),\n","            'params': {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3}\n","        },\n","        'Ridge_Regression': {\n","            'model': Ridge(alpha=1.0),\n","            'params': {'alpha': 1.0, 'solver': 'auto'}\n","        },'SVR': {\n","            'model': SVR(kernel='rbf', C=1.0,epsilon= 0.1),\n","            'params': {'kernel': 'rbf', 'C': 1.0, 'epsilon': 0.1}\n","        }\n","    }\n","\n","    results = {}\n","\n","    for name, model_info in models.items():\n","        with mlflow.start_run(run_name=f\"Regression_{name}\"):\n","            print(f\"\\n{'='*60}\")\n","            print(f\"Training and logging: {name}\")\n","            print(f\"{'='*60}\")\n","\n","            model = model_info['model']\n","            params = model_info['params']\n","\n","            # Log parameters\n","            mlflow.log_params(params)\n","            mlflow.log_param(\"model_type\", \"regression\")\n","            mlflow.log_param(\"algorithm\", name)\n","\n","            # Train model\n","            model.fit(X_train, y_train)\n","\n","            # Predictions\n","            y_pred_train = model.predict(X_train)\n","            y_pred_test = model.predict(X_test)\n","\n","            # Calculate metrics\n","            metrics = {\n","                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n","                'mae': mean_absolute_error(y_test, y_pred_test),\n","                'r2': r2_score(y_test, y_pred_test),\n","                'mape': mean_absolute_percentage_error(y_test, y_pred_test) * 100,\n","                'train_r2': r2_score(y_train, y_pred_train),\n","                'mse': mean_squared_error(y_test, y_pred_test)\n","            }\n","\n","            # Cross-validation\n","            cv_scores = cross_val_score(model, X_train, y_train, cv=5,\n","                                       scoring='neg_mean_squared_error')\n","            metrics['cv_rmse_mean'] = np.sqrt(-cv_scores.mean())\n","            metrics['cv_rmse_std'] = np.sqrt(cv_scores.std())\n","\n","            # Log metrics\n","            mlflow.log_metrics(metrics)\n","\n","            # Create and log actual vs predicted plot\n","            fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n","\n","            # Actual vs Predicted\n","            axes[0].scatter(y_test, y_pred_test, alpha=0.5)\n","            axes[0].plot([y_test.min(), y_test.max()],\n","                        [y_test.min(), y_test.max()], 'r--', lw=2)\n","            axes[0].set_xlabel('Actual Values')\n","            axes[0].set_ylabel('Predicted Values')\n","            axes[0].set_title(f'Actual vs Predicted - {name}')\n","\n","            # Residuals\n","            residuals = y_test - y_pred_test\n","            axes[1].scatter(y_pred_test, residuals, alpha=0.5)\n","            axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n","            axes[1].set_xlabel('Predicted Values')\n","            axes[1].set_ylabel('Residuals')\n","            axes[1].set_title(f'Residual Plot - {name}')\n","\n","            plt.tight_layout()\n","            mlflow.log_figure(fig, f\"prediction_plots_{name}.png\")\n","            plt.close()\n","\n","            # Log feature importance (if available)\n","            if hasattr(model, 'feature_importances_'):\n","                importance_df = pd.DataFrame({\n","                    'feature': feature_names,\n","                    'importance': model.feature_importances_\n","                }).sort_values('importance', ascending=False)\n","\n","                fig, ax = plt.subplots(figsize=(10, 6))\n","                importance_df.head(15).plot(x='feature', y='importance',\n","                                           kind='barh', ax=ax)\n","                ax.set_title(f'Top 15 Feature Importances - {name}')\n","                plt.tight_layout()\n","                mlflow.log_figure(fig, f\"feature_importance_{name}.png\")\n","                plt.close()\n","\n","                importance_df.to_csv(f\"feature_importance_{name}.csv\", index=False)\n","                mlflow.log_artifact(f\"feature_importance_{name}.csv\")\n","\n","            # Infer signature\n","            signature = infer_signature(X_train, model.predict(X_train))\n","\n","            # Log model\n","            # mlflow.sklearn.log_model(\n","            #     model,\n","            #     artifact_path=\"model\",\n","            #     signature=signature,\n","            #     registered_model_name=f\"EMI_Regression_{name}\"\n","            # )\n","\n","\n","            #Saving model locally\n","            joblib.dump(model, os.path.join(reg_models_path, f\"{name}_tuned.joblib\"))\n","\n","\n","            # Save prediction results\n","            results_df = pd.DataFrame({\n","                'Actual': y_test,\n","                'Predicted': y_pred_test,\n","                'Residual': residuals\n","            })\n","            results_df.to_csv(f\"predictions_tuned{name}.csv\", index=False)\n","            mlflow.log_artifact(f\"predictions_tuned{name}.csv\")\n","\n","            # Store results\n","            results[name] = {\n","                'model': model,\n","                'metrics': metrics,\n","                'run_id': mlflow.active_run().info.run_id\n","            }\n","\n","            print(f\"‚úì Model logged successfully!\")\n","            print(f\"  RMSE: {metrics['rmse']:.2f}\")\n","            print(f\"  R¬≤: {metrics['r2']:.4f}\")\n","\n","    return results"],"metadata":{"id":"0WKgDBvB80Nv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["** Training of models.."],"metadata":{"id":"8rYWTdXKfYXp"}},{"cell_type":"code","source":[],"metadata":{"id":"QbJRPUFVT9k7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zEpVuuXR9GZw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Classification models"],"metadata":{"id":"DhpG5IV-QyPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# clf_results= train_classification_models(x_train_clf, x_val_clf, y_train_clf, y_val_clf)"],"metadata":{"id":"lIrucUTmBBSv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# clf_models_evaluation_df=evaluate_classification_models(results=clf_results,y_test=y_val_clf)"],"metadata":{"id":"ZoouOrlaBIWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# clf_hyperpara_tuned_results= train_and_log_classification_models(x_train_clf, x_val_clf, y_train_clf, y_val_clf,feature_names=x_train_clf.columns.tolist(), experiment_name='Hyperpar_tuned_EMI_Classification')"],"metadata":{"id":"szV8iI7SPHGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# clf_tuned_models_evaluation_df=evaluate_classification_models(results=clf_hyperpara_tuned_results,y_test=y_val_clf)"],"metadata":{"id":"ltnWEfBRBIS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Regression models models"],"metadata":{"id":"DgEiTBIpBIPa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reg_results= train_regression_models(x_train_rg, x_val_rg, y_train_rg, y_val_rg)"],"metadata":{"id":"e55SZYIxQvmm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rg_models_evaluation_df=evaluate_regression_models(results=reg_results,y_test=y_val_rg)"],"metadata":{"id":"nx2rheTgQvmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rg_hyperpara_tuned_results= train_and_log_regression_models(x_train_rg, x_val_rg, y_train_rg, y_val_rg,feature_names=x_train_rg.columns.tolist())"],"metadata":{"id":"uAARst9LQvmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rg_models_evaluation_df=evaluate_regression_models(results=rg_hyperpara_tuned_results,y_test=y_val_rg)"],"metadata":{"id":"HlG8mBa0Qvmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GFtq2q9vBIMC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Registering models and production deployment"],"metadata":{"id":"2RIXC6cXCGKC"}},{"cell_type":"markdown","source":["def compare_and_select_best_models(classification_results, regression_results):\n","    \"\"\"\n","    Compare all models and select the best performing ones\n","    \"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"MODEL SELECTION AND COMPARISON\")\n","    print(\"=\"*80)\n","    \n","    # Classification Model Comparison\n","    print(\"\\nüìä CLASSIFICATION MODELS COMPARISON:\")\n","    print(\"-\" * 80)\n","    \n","    classification_comparison = []\n","    for name, result in classification_results.items():\n","        metrics = result['metrics']\n","        classification_comparison.append({\n","            'Model': name,\n","            'Accuracy': f\"{metrics['accuracy']:.4f}\",\n","            'Precision': f\"{metrics['precision']:.4f}\",\n","            'Recall': f\"{metrics['recall']:.4f}\",\n","            'F1-Score': f\"{metrics['f1_score']:.4f}\",\n","            'ROC-AUC': f\"{metrics['roc_auc']:.4f}\",\n","            'CV Accuracy': f\"{metrics['cv_accuracy_mean']:.4f} ¬± {metrics['cv_accuracy_std']:.4f}\",\n","            'Run ID': result['run_id']\n","        })\n","    \n","    classification_df = pd.DataFrame(classification_comparison)\n","    print(classification_df.to_string(index=False))\n","    \n","    # Find best classification model\n","    best_classification_idx = classification_df['ROC-AUC'].astype(float).idxmax()\n","    best_classification_model = classification_df.loc[best_classification_idx, 'Model']\n","    best_classification_auc = classification_df.loc[best_classification_idx, 'ROC-AUC']\n","    \n","    print(f\"\\nüèÜ Best Classification Model: {best_classification_model}\")\n","    print(f\"   ROC-AUC Score: {best_classification_auc}\")\n","    \n","    # Regression Model Comparison\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìä REGRESSION MODELS COMPARISON:\")\n","    print(\"-\" * 80)\n","    \n","    regression_comparison = []\n","    for name, result in regression_results.items():\n","        metrics = result['metrics']\n","        regression_comparison.append({\n","            'Model': name,\n","            'RMSE': f\"{metrics['rmse']:.2f}\",\n","            'MAE': f\"{metrics['mae']:.2f}\",\n","            'R¬≤': f\"{metrics['r2']:.4f}\",\n","            'MAPE (%)': f\"{metrics['mape']:.2f}\",\n","            'Train R¬≤': f\"{metrics['train_r2']:.4f}\",\n","            'CV RMSE': f\"{metrics['cv_rmse_mean']:.2f} ¬± {metrics['cv_rmse_std']:.2f}\",\n","            'Run ID': result['run_id']\n","        })\n","    \n","    regression_df = pd.DataFrame(regression_comparison)\n","    print(regression_df.to_string(index=False))\n","    \n","    # Find best regression model\n","    best_regression_idx = regression_df['R¬≤'].astype(float).idxmax()\n","    best_regression_model = regression_df.loc[best_regression_idx, 'Model']\n","    best_regression_r2 = regression_df.loc[best_regression_idx, 'R¬≤']\n","    \n","    print(f\"\\nüèÜ Best Regression Model: {best_regression_model}\")\n","    print(f\"   R¬≤ Score: {best_regression_r2}\")\n","    \n","    # Save comparison reports\n","    classification_df.to_csv('classification_models_comparison.csv', index=False)\n","    regression_df.to_csv('regression_models_comparison.csv', index=False)\n","    \n","    print(\"\\n‚úì Comparison reports saved!\")\n","    \n","    return {\n","        'best_classification': {\n","            'name': best_classification_model,\n","            'model': classification_results[best_classification_model]['model'],\n","            'metrics': classification_results[best_classification_model]['metrics'],\n","            'run_id': classification_results[best_classification_model]['run_id']\n","        },\n","        'best_regression': {\n","            'name': best_regression_model,\n","            'model': regression_results[best_regression_model]['model'],\n","            'metrics': regression_results[best_regression_model]['metrics'],\n","            'run_id': regression_results[best_regression_model]['run_id']\n","        }\n","    }\n","\n","# E. Model Registry and Production Deployment\n","def register_production_models(best_models):\n","    \"\"\"\n","    Register best models to MLflow Model Registry for production\n","    \"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"MODEL REGISTRY - PRODUCTION DEPLOYMENT\")\n","    print(\"=\"*80)\n","    \n","    from mlflow.tracking import MlflowClient\n","    client = MlflowClient()\n","    \n","    # Register Classification Model\n","    classification_name = best_models['best_classification']['name']\n","    classification_run_id = best_models['best_classification']['run_id']\n","    \n","    print(f\"\\nüì¶ Registering Classification Model: {classification_name}\")\n","    \n","    model_uri_classification = f\"runs:/{classification_run_id}/model\"\n","    model_details_classification = mlflow.register_model(\n","        model_uri=model_uri_classification,\n","        name=f\"EMI_Classification_Production\"\n","    )\n","    \n","    # Transition to Production\n","    client.transition_model_version_stage(\n","        name=\"EMI_Classification_Production\",\n","        version=model_details_classification.version,\n","        stage=\"Production\",\n","        archive_existing_versions=True\n","    )\n","    \n","    # Add model description\n","    client.update_model_version(\n","        name=\"EMI_Classification_Production\",\n","        version=model_details_classification.version,\n","        description=f\"Best performing classification model: {classification_name}. \"\n","                   f\"ROC-AUC: {best_models['best_classification']['metrics']['roc_auc']:.4f}\"\n","    )\n","    \n","    print(f\"‚úì Classification model registered as version {model_details_classification.version}\")\n","    print(f\"‚úì Model transitioned to Production stage\")\n","    \n","    # Register Regression Model\n","    regression_name = best_models['best_regression']['name']\n","    regression_run_id = best_models['best_regression']['run_id']\n","    \n","    print(f\"\\nüì¶ Registering Regression Model: {regression_name}\")\n","    \n","    model_uri_regression = f\"runs:/{regression_run_id}/model\"\n","    model_details_regression = mlflow.register_model(\n","        model_uri=model_uri_regression,\n","        name=f\"EMI_Regression_Production\"\n","    )\n","    \n","    # Transition to Production\n","    client.transition_model_version_stage(\n","        name=\"EMI_Regression_Production\",\n","        version=model_details_regression.version,\n","        stage=\"Production\",\n","        archive_existing_versions=True\n","    )\n","    \n","    # Add model description\n","    client.update_model_version(\n","        name=\"EMI_Regression_Production\",\n","        version=model_details_regression.version,\n","        description=f\"Best performing regression model: {regression_name}. \"\n","                   f\"R¬≤: {best_models['best_regression']['metrics']['r2']:.4f}\"\n","    )\n","    \n","    print(f\"‚úì Regression model registered as version {model_details_regression.version}\")\n","    print(f\"‚úì Model transitioned to Production stage\")\n","    \n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úÖ PRODUCTION MODELS SUCCESSFULLY DEPLOYED!\")\n","    print(\"=\"*80)\n","    \n","    return {\n","        'classification': model_details_classification,\n","        'regression': model_details_regression\n","    }\n","\n","# F. Load Production Models for Inference\n","def load_production_models():\n","    \"\"\"\n","    Load production models from MLflow Model Registry\n","    \"\"\"\n","    print(\"\\nüì• Loading Production Models from Registry...\")\n","    \n","    # Load Classification Model\n","    classification_model = mlflow.pyfunc.load_model(\n","        model_uri=\"models:/EMI_Classification_Production/Production\"\n","    )\n","    print(\"‚úì Classification model loaded\")\n","    \n","    # Load Regression Model\n","    regression_model = mlflow.pyfunc.load_model(\n","        model_uri=\"models:/EMI_Regression_Production/Production\"\n","    )\n","    print(\"‚úì Regression model loaded\")\n","    \n","    return {\n","        'classification': classification_model,\n","        'regression': regression_model\n","    }\n","\n","# G. Model Inference Function\n","def predict_emi_eligibility_and_amount(new_data, scaler=None):\n","    \"\"\"\n","    Make predictions using production models\n","    \"\"\"\n","    # Load production models\n","    models = load_production_models()\n","    \n","    # Preprocess new data\n","    if scaler:\n","        new_data_scaled = scaler.transform(new_data)\n","    else:\n","        new_data_scaled = new_data\n","    \n","    # Classification prediction\n","    eligibility_prediction = models['classification'].predict(new_data_scaled)\n","    eligibility_proba = models['classification'].predict_proba(new_data_scaled)\n","    \n","    # Regression prediction\n","    emi_amount_prediction = models['regression'].predict(new_data_scaled)\n","    \n","    results = pd.DataFrame({\n","        'EMI_Eligible': eligibility_prediction,\n","        'Eligibility_Probability': eligibility_proba[:, 1],\n","        'Predicted_EMI_Amount': emi_amount_prediction\n","    })\n","    \n","    return results"],"metadata":{"id":"IxQ2Se7lBCDu"}},{"cell_type":"markdown","source":["# ** Best model selection process"],"metadata":{"id":"v6Qjxa3SooN2"}},{"cell_type":"code","source":["def clf_model_analysis(model,model_name):\n","  print(f\"{'='*20}{model_name.split()[0]}{'='*20}\\n\")\n","  y_preds_train=model.predict(x_train_clf)\n","  print(f\"train_accuracy:{accuracy_score(y_train_clf,y_preds_train)}\")\n","  y_preds_val=model.predict(x_val_clf)\n","  print(f\"val_accuracy:{accuracy_score(y_val_clf,y_preds_val)}\")\n","  y_pred_test=model.predict(x_test_clf)\n","  print(f\"test_accuracy:{accuracy_score(y_test_clf,y_pred_test)}\\n\")\n"],"metadata":{"id":"afbJXXINslVv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"t6IX33GQ4MaJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def reg_model_analysis(model,model_name):\n","  print(f\"{'='*20}{model_name}{'='*20}\\n\")\n","  y_preds_train=model.predict(x_train_rg)\n","  print(f\"train_RMSE:{np.sqrt(mean_squared_error(y_train_rg,y_preds_train))}\")\n","  y_preds_val=model.predict(x_val_rg)\n","  print(f\"val_RMSE:{np.sqrt(mean_squared_error(y_val_rg,y_preds_val))}\")\n","  y_pred_test=model.predict(x_test_rg)\n","  print(f\"test_RMSE:{np.sqrt(mean_squared_error(y_test_rg,y_pred_test))}\\n\")\n"],"metadata":{"id":"GYSqA9Vi1ySi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf_dir_list=os.listdir('/content/drive/MyDrive/Labmentix intern projects/EMIPredict AI /Models/clf_models')"],"metadata":{"id":"N8utwKufv78y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf_dir_list"],"metadata":{"id":"h6jgA1Fbzc_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for model_name in clf_dir_list:\n","  model=joblib.load(f'/content/drive/MyDrive/Labmentix intern projects/EMIPredict AI /Models/clf_models/{model_name}')\n","  clf_model_analysis(model,model_name=model_name)"],"metadata":{"id":"uYlM7Q-5wH05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg_dir_list=os.listdir('/content/drive/MyDrive/Labmentix intern projects/EMIPredict AI /Models/reg_models')"],"metadata":{"id":"Fg2SaaNW2vzw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg_dir_list"],"metadata":{"id":"IxDTBzNI2-iH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for model_name in reg_dir_list:\n","  model=joblib.load(f'/content/drive/MyDrive/Labmentix intern projects/EMIPredict AI /Models/reg_models/{model_name}')\n","  reg_model_analysis(model,model_name=model_name)"],"metadata":{"id":"6-DTIFck3CHP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üü¢ Best Generalising Classification Models\n","\n","## ‚úÖ 1. XGBoost (Tuned) --- **BEST GENERALISATION**\n","\n","**Performance:** - Train = **0.9716** - Val = **0.9707** - Test =\n","**0.9725**\n","\n","### ‚úî Why it Generalizes Best?\n","\n","-   Very small train--validation--test gap\n","-   Strong regularization (max_depth, learning_rate)\n","-   High accuracy + low variance\n","-   Handles imbalance and noise effectively\n","-   Industry-standard for generalization capability\n","\n","‚û° **Most generalizable model in your results.**\n","\n","------------------------------------------------------------------------\n","\n","## ‚úÖ 2. Logistic Regression (Tuned) --- **MOST STABLE & SIMPLE**\n","\n","**Performance:** - Train = **0.8988** - Val = **0.8975** - Test =\n","**0.8991**\n","\n","### ‚úî Why it Generalizes Well?\n","\n","-   The smallest possible gap across splits\n","-   Extremely low overfitting risk\n","-   Highly interpretable linear decision boundary\n","-   Best choice for explainability and stability\n","\n","‚û° **Safest low-variance generalizing model.**\n","\n","------------------------------------------------------------------------\n","\n","# üèÜ Final Generalization Recommendation\n","\n","### üîπ If you want the **MOST generalizable + highest accuracy** model:\n","\n","## ‚≠ê **XGBoost (Tuned)**\n","\n","### üîπ If you want the **MOST stable + interpretable** model:\n","\n","## ‚≠ê **Logistic Regression (Tuned)**\n","\n","------------------------------------------------------------------------\n","\n","# üìä Summary Table\n","\n","  -------------------------------------------------------------------------------\n","  Model         Generalization Quality                         Why\n","  ------------- ---------------------------------------------- ------------------\n","  **XGBoost     ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê                                     Best trade-off:\n","  (Tuned)**                                                    accuracy +\n","                                                               regularization +\n","                                                               low variance\n","\n","  **Logistic    ‚≠ê‚≠ê‚≠ê‚≠ê                                       Most stable,\n","  Regression                                                   simplest boundary,\n","  (Tuned)**                                                    minimal\n","                                                               overfitting\n","\n","  **Gradient    ‚≠ê‚≠ê‚≠ê‚≠ê                                       Strong but\n","  Boosting                                                     slightly less\n","  (Tuned)**                                                    generalizing than\n","                                                               XGB\n","\n","  **Random      ‚≠ê‚≠ê‚≠ê                                         Good stability but\n","  Forest                                                       lower performance\n","  (Tuned)**                                                    \n","\n","  **Decision    ‚≠ê                                             Overfits in\n","  Tree**                                                       general despite\n","                                                               good metrics\n","  -------------------------------------------------------------------------------\n","\n","------------------------------------------------------------------------\n","\n","# üìå Conclusion\n","\n","For your classification problem: - **XGBoost (Tuned)** ‚Üí Best for high\n","accuracy + strong generalization\\\n","- **Logistic Regression (Tuned)** ‚Üí Best for stability, simplicity, and\n","interpretability\n"],"metadata":{"id":"x9dKbJGzr6JG"}},{"cell_type":"markdown","source":["# ‚úÖ Best Regression Model (Most Accurate + Most Generalized)\n","\n","## ‚≠ê Random Forest (Untuned)\n","\n","### **Why?**\n","\n","-   **Lowest RMSE among all models**\n","    -   Train: **526**\n","    -   Validation: **490**\n","    -   Test: **529**\n","-   Very small train--test gap ‚Üí **excellent generalization**\n","-   Performs significantly better than boosted and linear models\n","-   Low bias + low variance due to ensemble averaging\n","\n","‚û° **This is the strongest model in your results.**\n","\n","------------------------------------------------------------------------\n","\n","## ü•à Second Best Model\n","\n","### ‚≠ê XGBoost (Untuned)\n","\n","-   Train: **621**\n","-   Val: **597**\n","-   Test: **628**\n","-   Good generalization but slightly worse RMSE than Random Forest\n","-   More stable than Decision Tree\n","\n","------------------------------------------------------------------------\n","\n","## ‚ö†Ô∏è Models to Avoid\n","\n","### ‚ùå Linear Regression / Tuned Linear / Ridge Regression\n","\n","-   RMSE ‚âà **4000** ‚Üí Model not fitting data at all\\\n","-   Indicates:\n","    -   Strong non-linear relationships\\\n","    -   Feature interactions\\\n","    -   High complexity\\\n","-   Not suitable for this dataset\n","\n","### ‚ùå Decision Tree\n","\n","-   Low train RMSE but much higher test RMSE\\\n","-   **Overfitting**\\\n","-   Avoid unless pruned or regularized\n","\n","------------------------------------------------------------------------\n","\n","## ‚≠ê Tuned Models Performance\n","\n","  ------------------------------------------------------------------------\n","  Model       Train RMSE          Test RMSE          Observation\n","  ----------- ------------------- ------------------ ---------------------\n","  Random      1366                1335               Worse than untuned\n","  Forest                                             \n","  (Tuned)                                            \n","\n","  Gradient    1404                1350               High error\n","  Boosting                                           \n","  (Tuned)                                            \n","\n","  XGBoost     714                 707                Worse than untuned\n","  (Tuned)                                            due to\n","                                                     over-regularization\n","  ------------------------------------------------------------------------\n","\n","‚û° **Tuned parameters reduced model capacity ‚Üí higher error.**\n","\n","------------------------------------------------------------------------\n","\n","# üèÜ Final Recommendation Summary\n","\n","  -------------------------------------------------------------------------\n","  Rank         Model            Performance                Reason\n","  ------------ ---------------- -------------------------- ----------------\n","  **1 (Best)** Random Forest    ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê                 Best RMSE + Best\n","               (Untuned)                                   generalization\n","\n","  **2**        XGBoost            ‚≠ê‚≠ê‚≠ê‚≠ê                   Strong, stable\n","               (Untuned)                                   model\n","\n","  **3**        Decision Tree    ‚≠ê‚≠ê‚≠ê                     Moderate, but\n","                                                           overfits\n","\n","  **4**        Gradient         ‚≠ê‚≠ê                       Higher error\n","               Boosting/Tuned                              \n","               Models                                      \n","\n","  **5          Linear / Ridge   ‚≠ê                         Model not\n","  (Worst)**    Regression                                  fitting data\n","  -------------------------------------------------------------------------\n","\n","------------------------------------------------------------------------\n","\n","## üìå Final Recommendation (For Project Report)\n","\n","### ‚úî For Highest Accuracy + Best Generalization\n","\n","### ‚≠ê **Random Forest (Untuned)**\n","\n","### ‚úî For Backup Model\n","\n","### ‚≠ê **XGBoost (Untuned)**\n"],"metadata":{"id":"ZGL2xLC8rjOo"}}]}